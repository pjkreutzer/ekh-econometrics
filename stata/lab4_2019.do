***************************************************************************************************
*                                                                                                 *
*    LAB 4: ASSUMPTIONS, HP TESTING, DUMMY VARIABLES, CATEGORICAL VARIABLES, & TRANSFORMATIONS    *
*                                                                                                 *
***************************************************************************************************

/*
AFTER DOWNLOADING THE DATA AND DO FILE TO THE SAME FOLDER, THE FIRST THING WE NEED 
TO DO IS CHANGE THE WORKING DIRECTORY. 
THEN, WE NEED TO OPEN THE DO FILE, AND LASTLY THE DATA.
YOU MAY ALSO START A LOG FILE IF YOU WISH.
*/

cd "C:\Users\jo1173an\econometrics i"
use "lab4_2019_cars", clear
log using "lab4.log"


*****SECTION I. SIMPLE LINEAR REGRESSION - CONTINUED*****

/*
LET'S CONTINUE FROM WHERE WE HAVE LEFT IN LAB 3:

YOU ARE INTERESTED IN UNDERSTANDING THE RELATIONSHIP BETWEEN A VEHICLE'S FUEL EFFICIENCY (COMBINED MILES PER GALLON) AND ITS WEIGHT.
TO DO THIS, WE HAVE DECIDED TO RUN A SIMPLE LINEAR REGRESSION: y_i = a + BX_i + e
OUR VARIABLES ARE: Y_i = COMBINED MILES PER GALLON AND X_i = WEIGHT.
*/

/*
FIRST, IF WE DON'T HAVE THE VARIABLE WE NEED WE MAY NEED TO GENERATE IT OURSELVES.
IN THIS CASE, WE NEED TO FIGURE OUT THE COMBINED MILES PER GALLON.
COMBINED MILES PER GALLON = 1 / ((.45/HIGHWAY MPG) + (.55/CITY MPG))
*/
gen combined = 1/((.55/city) + (.45/high))
label var combined "Avg fuel efficiency"
br city high combined

* WE SHOULD EXAMINE OUR NEW VARIABLE TO SEE THAT IT WAS CORRECTLY DEFINED.
sum combined, detail

/*
THE VARIABLE SEEMS PROPERLY CALCULATED (THERE ARE NO VALUES THAT SEEM UNREASONABLE).
IT IS ALWAYS IMPORTANT TO CHECK WHETHER VARIABLES YOU CREATE ARE REASONABLE 

WE SHOULD ALSO LOOK AT THE TWO VARIABLES OF INTEREST FOR AN IDEA OF THEIR RELATIONSHIP.
WE CAN DO THAT BY LOOKING AT THE CORRELATION AND BY DRAWING A TWOWAY GRAPH
*/
corr combined weight
twoway (scatter combined weight) (lfit combined weight)

/*
IT SEEMS LIKE THERE IS A NEGATIVE ASSOCIATION BETWEEN THE VARIABLES.
NOW THAT WE HAVE EXAMINED THE DATA, WE WANT TO TRY OUT OUR MODEL.
REMEMBER THAT WE ARE LOOKING AT CARS NOT PEOPLE (I.E. UNIT OF OBSERVATION = CARS), 
AND ALL OF YOUR ANALYSIS SHOULD KEEP THIS IN MIND.
*/
reg combined weight

/*
*******OVERALL MODEL FIT*******

F = F-STATISTIC (CALCULATED: MS MODEL / MS RESIDUAL)
PROB > F = THE P-VALUE ASSOCIATED WITH THE F-STAT.  IT IS USED IN TESTING THE MODEL SIGNIFICANCE. 
THE NULL HYPOTHESIS OF F-TEST: 
R-SQUARED:
ADJ R-SQUARED:
ROOT MSE = STANDARD DEVIATION OF THE ERROR TERM (SQUARE ROOT OF THE MEAN SQUARES RESIDUAL)

OUR MODEL IS SIGNIFICANT AT a = 0.01 
(F-TEST=617.75; p= 0.0000; I.E. WE REJECT H0 THAT THERE IS NO LINEAR RELATIONSHIP BETWEEN INDEPENDENT AND DEPENDENT VARIABLES).

*******T-TEST*******

OUR COEFFICIENT b= -.00583 IS SIGNIFICANT AT a=0.01
WE REJECT THE NULL HYPOTHESIS THAT b=0

WHAT IS THE P-VALUE TELLING US HERE?
HOW CONFIDENT CAN WE BE THAT WE ARE NOT COMMITTING A TYPE 1 ERROR?
WHAT ABOUT THE CONFIDENCE INTERVALS?

TYPE 1 ERROR: WE REJECT THE NULL HYPOTHESIS WHEN IN REALITY, IT IS TRUE
TYPE 2 ERROR: WE RETAIN THE NULL HYPOTHESIS WHEN IN REALITY, IT IS FALSE


BUT BEFORE WE CAN MAKE ANY CONCLUSIONS WE NEED TO CHECK THE PROPERTIES OF THE MODEL TO BE SURE IT FULFILLS THE OLS ASSUMPTIONS.

YOU'LL RECALL THAT THE OLS ESTIMATOR IS ONLY 'BLUE' (BEST LINEAR UNBIASED ESTIMATE) WHEN CERTAIN ASSUMPTIONS ARE FULFILLED.

ASSUMPTIONS ABOUT 
 - NO AUTOCORRELATION, 
 - INDEPENDENCE OF X'S AND 
 - THE MODEL BEING LINEAR IN ITS PARAMETERS 
ARE TYPICALLY FULFILLED IN CROSS SECTIONAL DATA AND OFTEN DO NOT NEED TO BE FORMALLY TESTED.

IN SIMPLE LINEAR REGRESSION, 
 - MULTICOLLINEARITY 
IS NOT A PROBLEM, SINCE WE ONLY HAVE ONE PREDICTOR (INDEPENDENT VARIABLE).

ONE WAY TO DETERMINE IF OUR ESTIMATE IS BLUE IS BY LOOKING AT THE RESIDUALS AND FITTED VALUES.
*/

/*
****TESTING FOR NORMALITY IN THE RESIDUALS****

WE SHOULD TEST FOR NORMALITY IN THE RESIDUALS. THIS CAN BE DONE MULTIPLE WAYS.

THE 'predict' COMMAND TELLS STATA TO USE THE PARAMETERS WE ESTIMATED TO GENERATE A NEW VARIABLE.
FIRST, STATA PREDICTS THE RESIDUALS (I.E. THE DISTANCE BETWEEN OUR REGRESSION LINE AND OUR DATA POINTS).
*/
predict e, resi

*SECOND, STATA PREDICTS FITTED VALUES OF Y (IN THIS CASE THE COMBINED GAS MILEAGE OF THE VEHICLE).
predict yhat

/*
ONE NECESSARY THOUGH INSUFFICIENT INDICATOR OF NORMALITY IS THAT MOST OBSERVATIONS 
(ABOUT 95%) FALL WITHIN 2 STANDARD DEVIATIONS OF THE MEAN.
THIS IS A CHARACTERISTIC OF A NORMAL DISTRIBUTION (A.K.A. THE 68-95-99.7 RULE)
*/
egen stdevplus= sd(e)
replace stdevplus=stdevplus*2
gen stdevmin=-1*stdevplus
twoway (scatter e yhat) (lfit e yhat) (line stdevmin yhat) (line stdevplus yhat)
/*
HERE OUR GRAPH INDICATES THAT THE SCATTER OF OUR DATA POINTS FALLS INCONSISTENTLY WITHIN THE APPROPRIATE RANGE
IT DOES NOT, HOWEVER, CONFIRM NON-NORMALITY AND FORMAL TESTS ARE REQUIRED
*/

hist e, norm percent bin (25)
/*
THE HISTOGRAM OVERLAYED WITH A NORMAL DISTRIBUTION DOES NOT SEEM TO INDICATE NORMALITY IN THE RESIDUALS.
THERE IS A POSITIVE SKEW PRESENT ALTHOUGH IT IS QUITE CLOSE
*/

qnorm e
/*
IF THE RESIDUALS ARE NORMALLY DISTRIBUTED, THEY SHOULD MORE OR LESS FOLLOW THE STRAIGHT LINE OF THE Q-Q PLOT
IN THIS CASE, THE RESIDUALS DEVIATE SLIGHTLY BIT FROM THE NORMAL DISTRIBUTION AROUND THE TAILS.
*/

sktest e, noadjust
/*
WE DON'T JUST NEED TO USE GRAPHICS TO GAUGE NORMALITY.  WE CAN ALSO USE A FORMAL TEST FOR NORMALITY.
THIS IS A TEST OF THE NULL HYPOTHESIS H0: variable is normally distributed 
HERE WE REJECT THAT THE VARIABLE IS NORMALLY DISTRIBUTED (p=0.000).  
*/


jb6 e

* HERE AGAIN WE REJECT THE NULL HYPOTHESIS OF NORMALITY AT .001





****CORRECTING FOR NON-NORMALITY IN THE RESIDUALS****
/*
AT THIS POINT WE HAVE CONCLUDED THAT THE RESIDUALS ARE NOT NORMALLY DISTRIBUTED.
SIMPLE SOLUTION FOR IMPROVING NON-NORMALLY DISTRIBUTED RESIDUALS: LOGARITHMS!
THIS ALSO MAKES FOR A SIMPLE INTERPRETATION OF THE BETA COEFFICIENTS AS ELASTICITIES WHEN THE VARIABLES ARE CONTINUOUS.
*/
gen lncom = ln(combined)
gen lnweight = ln(weight)

reg lncom lnweight
predict e2, res
predict yhat2
twoway (scatter e2 yhat2) (lfit e2 yhat2)
hist e2, norm bin(10)
* THIS HISTOGRAM LOOKS A BIT CLOSER TO A NORMAL DISTRIBUTION.

sktest e2
jb6 e2
sktest e
jb6 e

/*
AND THE TEST FOR NORMALITY STILL REJECTS H0: NORMAL DISTRIBUTION
THIS IS MUCH CLOSER TO NOT REJECTING THE NULL THAN BEFORE (SEE CHI2 VALUE)
PRIOR TO THE LOG ADJUSTMENT, THE DISTRIBUTION WAS ALSO CLOSE TO NORMALLY DISTRIBUTED

YOU SHOULDN'T ONLY RELY ON TESTS WHEN GRAPHICAL EVIDENCE POINTS IN THE OPPOSITE DIRECTION.
YOU NEED TO USE YOUR JUDGEMENT.
*/


/*
A WORD ABOUT COEFFICIENTS & REAL WORLD SIGNIFICANCE

BEFORE OUR COEFFICIENT WAS b=-.0058 IN THE LINEAR-LINEAR MODEL. 
INTEPRETATION: A 1 UNIT INCREASE IN THE VEHICLES WEIGHT LEADS TO A .0058 UNIT DECREASE IN ITS COMBINED MPG.

OUR NEW COEFFICIENT IS b=-0.9341 IN THE LOG-LOG MODEL. 
INTERPRETATION: A 10% INCREASE IN THE WEIGHT OF A VEHICLE IS ASSOCIATED WITH ROUGHLY A 9.34% DECREASE 
IN ITS COMBINED MPG.
  
IF WE LOOK AT OUR R^2 VALUE, 77.95% OF THE VARIANCE IN Y_I IS EXPLAINED BY X_I.
SINCE WE HAVE MORE DATA AVAILABLE, WE CAN STRIVE TO IMPROVE THE FIT OF OUR MODEL.
*/


drop e* yhat* stdev*
/*
PUTTING AN ASTERISK (*) AFTER SOMETHING WILL TELL STATA DO DROP EVERYTHING THAT BEGINS WITH WHATEVER COMES BEFORE THE ASTERISK.
IN THIS CASE, WHEN WE SAY 'drop yhat*' WE ARE TELLING STATA DO DROP ALL VARIABLES BEGINNING WITH 'yhat'.
USE CAUTIOUSLY!
*/





*****SECTION II. MULTIPLE LINEAR REGRESSION*****




/*
WE WANT TO SEE IF WE CAN IMPROVE OUR MODEL BY INCLUDING SOME OTHER IMPORTANT COVARIATES SUCH AS: 
HORSEPOWER, VEHICLE LENGTH, SIZE OF THE FUEL TANK, AND NUMBER OF CYLINDERS
IN THIS REGRESSION WE WILL HAVE LINEAR INDEPENDENT VARIABLES.
*/

rename horse_power hpower
reg combined weight length fuel hpower cylinder

/*
LOOK OVER THE ANOVA TABLE AND THE OVERALL MODEL FIT
WHAT ARE THEY TELLING US? 

IN THIS CASE, HOW CAN THE COEFFICIENTS BE INTERPRETED?

MOST OF OUR COVARIATES ARE STATISTICALLY SIGNIFICANT AT THE OR 5% LEVEL AND OUR R^2 INCREASED (R^2= 0.7804).
OUR F-TEST TELLS US THAT SOMETHING IN THE MODEL IS SIGNIFICANTLY PREDICTING OUR OUTCOME VARIABLE.

WHAT CAN WE SAY WITH CERTAINTY ABOUT THE COEFFICIENT FOR 'fuel'?

WE STILL HAVE TO DO THE STANDARD DIAGNOSTICS, BUT NOW WE NEED TO ALSO CHECK FOR MULTICOLLINEARITY, SINCE THERE ARE MULTIPLE COVARIATES.
*/

predict e, res
predict yhat

egen stdevplus= sd(e)
replace stdevplus=stdevplus*2
gen stdevmin=-1*stdevplus
twoway (scatter e yhat) (lfit e yhat) (line stdevmin yhat) (line stdevplus yhat)

* WHAT DO WE SEE HERE?


jb6 e
sktest e, noadjust
hist e, norm percent bin (25)

* ALTHOUGH THE TESTS STATE THAT THE RESIDUALS ARE NOT NORMALLY DISTRIBUTED, THE GRAPHICAL EVALUATION SHOWS A NEARLY NORMAL DISTRIBUTION

drop e yhat








****HYPOTHESIS TESTING****

reg combined weight length fuel hpower cylinder 

 
test fuel==0
/*
WE SEE THAT 'fuel' IS NOT SIGNIFICANT, BUT WHAT DOES THIS MEAN?
NOW LETS GO BACK AND TAKE A LOOK AT THE PREVIOUSLY SPECIFIED MODEL
LOOK AT THE P-VALUE IN THE REGRESSION OUTPUT AND COMPARE IT TO THE F-TEST
*/

test hpower==0
test cylinder==hpower

/*
IN THIS CASE WE REJECT THE NULL THAT hpower == 0

WE ALSO REJECT THE NULL  THAT cylinder=hpower.  IN OTHER WORDS, 
THERE IS A STATISTICALLY SIGNIFICANTLY DIFFERENT IMPACT FROM THESE TWO VARIABLES.
THE F-TEST IN THE ANOVA TABLE ONLY TELLS US THAT SOMETHING IN THE MODEL 
HAS A SIGNIFICANT RELATIONSHIP WITH THE DEPENDENT VARIABLE, BUT NOT WHICH VARIABLE.
*/

* WE CAN ALSO TEST WHETHER COEFFICIENTS ARE STATISTICALLY DIFFERENT THAN VALUES OTHER THAN 0.

test weight==1

test weight == -.0042
* SINCE -.0042 IS WITHIN THE 95% CONFIDENCE INTERVAL, WE CANNOT BE SURE THAT THE COEFFICIENT ESTIMATED IS STATISTICALLY DIFFERENT THAN THAT VALUE

* FINALLY WE CAN TEST THE JOINT SIGNIFICANCE OF OUR ESTIMATES
test weight hpower cylinder fuel length
* HERE YOU ARE TESTING THE NULL HYPOTHESIS THAT ALL COVARIATES ARE ZERO AGAINST THE ALTERNATIVE HYPOTHESIS THAT AT LEAST ONE OF THEM IS DIFFERENT THAN ZERO

reg combined weight length fuel hpower cylinder 
test weight length fuel hpower cylinder 
* WITH THIS IN MIND LOOK AT THE F-STAT AND F-TEST BETWEEN THIS SPECIFICATION AND THE INITIAL REGRESSION

* BASED ON THIS REGRESSION, WHAT CAN WE CONCLUDE?
* A ONE UNIT INCREASE IN WEIGHT IS ASSOCIATED WITH A .0047 UNIT DECREASE IN THE COMBINED GAS MILEAGE
* GO AHEAD AND INTERPRET THE COEFFICIENTS FOR 'fuel' AND 'length'












************SECTION III. CATEGORICAL VARIABLES***************







/*
IN THIS SECTION WE WILL BE USING THE CURRENT POPULATION SURVEY FROM MARCH, 2012 CONDUCTED 
BY THE U.S. CENSUS BUREAU. THIS DATASET IS MUCH LARGER THAN THE LAST ONE WE USED, 
BUT EVERYTHING WE LEARNED BEFORE STILL APPLIES.
THE EXTRACTION INCLUDES ONLY INDIVIDUALS AGE 18 TO 65.
*/
use "lab4_2019_income.dta", clear

* AFTER THE DATASET IS OPENED, WE SHOULD DO OUR BASIC EXAMINATION OF THE DATA.
sum
describe
label list

/*
FOR THIS LAB, WE WOULD LIKE TO EXAMINE HOW SEVERAL DEMOGRAPHIC AND ECONOMIC 
VARIABLES IMPACT AN INDIVIDUAL'S TOTAL INCOME.
NOTE THAT OUR UNIT OF ANALYSIS IS NOW INDIVIDUALS AND NOT CARS AS IN THE PREVIOUS LAB. 
WHEN CONSIDERING THE ASSOCIATION OF DEMOGRAPHIC CHARACTERISTICS AND ECONOMIC 
OUTCOMES IT DOES NOT MAKE SENSE TO TREAT ALL EXPLANATORY VARIABLES AS CONTINUOUS VARIABLES.
IN THESE CASES, WE NEED TO USE CATEGORICAL VARIABLES.
*/
drop if inctot<0

/*
IN THIS CASE, WE ARE INTERESTED IN EXAMINING THE ASSOCIATIONS OF SEX, AGE, RACE, 
MARITAL STATUS, INDUSTRIAL SECTOR AND EDUCATION WITH TOTAL INCOME WHEN CONTROLLING FOR OTHER FACTORS.

ONE THING WE MAY NEED TO TAKE INTO ACCOUNT WHEN DOING THIS STUDY IS THE 
NUMBER OF ADULTS IN A HOUSEHOLD, AS THIS CAN AFFECT AN INDIVIDUAL'S TOTAL INCOME.
WHEN WE BROWSE FAMILIES, WE SEE THAT THERE ARE SOMETIMES SEVERAL ADULTS IN A SAMPLE FAMILY.
*/
br serial age

/*
BECAUSE MULTIPLE ADULTS IN A HOUSEHOLD MAY HAVE SEVERAL IMPLICATIONS FOR 
INDIVIDUAL INCOME (I.E. LOW PAYING JOBS, RENT COLLECTION, ETC.), 
WE WANT TO CONTROL FOR THIS IN OUR REGRESSION
FIRST, WE SORT BY FAMILY TO BE SURE ALL MEMBERS OF A FAMILY ARE LISTED TOGETHER("SERIAL")
*/
sort serial
br serial

/*
SECOND, WE USE THE -BY- COMMAND TO LIMIT OUR COMMAND TO WITHIN EACH FAMILY.  
THE "_N" FUNCTION WILL FILL IN THE TOTAL NUMBER OF OBSERVATIONS WITHIN EACH 
GROUP (IN THIS CASE 'serial') IN THE CELLS WITHIN THAT GROUP.
*/
by serial: gen adultsinhh=_N
label var adultsinhh "Number of aduts in household"
br serial age adultsinhh

tab adultsinhh

/*
NOW WE HAVE A FAMILY SPECIFIC CHARACTERISTIC (ADULTS IN THE HOUSEHOLD), 
THAT WE CAN USE AS A CONTROL VARIABLE.

THERE IS ALSO "_n" FUNCTION THAT COUNTS A VARIABLE AS IT IS SORTED.
*/
by serial: gen n=_n
br serial age n adultsinhh
drop n

sort serial age
by serial: gen n=_n
br serial age n adultsinhh
drop n
/*
YOU CAN ALSO COMBINE sort AND by COMMANDS IN ONE AND USE bysort, FOR EXAMPLE:
bysort serial: gen adultsinhh=_N
*/


/* 
WE WANT TO BE ABLE TO BREAK INDVIDUALS INTO SECTORS, BUT RIGHT NOW WE JUST HAVE MANY INDUSTRY CODES.  
THIS ISN'T PRACTICAL TO WORK WITH.
SINCE A PORTION OF THE SAMPLE HAS NO INDUSTRY ASSIGNED TO THEM, 
WE CAN MAKE A NOTE OF THIS TO EXCLUDE THEM FROM OUR SAMPLE.
THE INDUSTRY CODES ARE AVAILABLE ON THIS WEBSITE:  
https://cps.ipums.org/cps/codebooks.shtml GO TO "2012 CPS ASEC Codebook"
*/
tab indly
gen industryflag= (indly==0)
tab industryflag
drop if industryflag==1
drop industryflag

/*
REMEMBER, IT IS NOT ALWAYS APPROPRIATE TO DROP MISSING OBSERVATIONS.  
SOMETIMES MISSING INFORMATION ACTUALLY DOES TELL US SOMETHING!
*/

gen sector=.
replace sector=1 if indly>1 & indly<500
replace sector=2 if indly>500 & indly<4000
replace sector=3 if indly>4000
label define sector_lbl 1 "primary" 2 "secondary" 3 "tertiary"
label val sector sector_lbl 
label var sector "Job sector categories"
tab sector

/* 
WE SHOULD ALSO, GENERATE "RACE" AS CATEGORICAL VARIABLE AT A HIGHER LEVEL OF AGGREGATION TO MAKE IT PRACTICAL TO WORK WITH.  
WE WILL DEFINE OUR CATEGORIES AS 1= WHITE, 2=BLACK, 3=NATIVE AMERICAN, 4= ASIAN OR PACIFIC ISLANDER, 5= 2 OR MORE RACES
*/

label list race_lbl

gen race_cat=. 
replace race_cat=1 if race==100
replace race_cat=2 if race==200
replace race_cat=3 if race==300
replace race_cat=4 if race>=650 & race<=652
replace race_cat=5 if race>652
label define race_cat_lbl 1 "White" 2 "African American" 3 " Native American" 4 " Asian/Pacific Islander" 5 "two or more races"
label val race_cat race_cat_lbl
label var race_cat "Racial categories"
tab race_cat

*WE WILL ALSO WANT TO USE INFORMATION ON EDUCATION, AS THERE IS PROBABLY NO STRONGER CORRELATION THAN BETWEEN EDUCATION AND PERSONAL INCOME.

label list educ99_lbl

gen edu_cat= .
replace edu_cat=1 if educ99<10
replace edu_cat=2 if educ99==10
replace edu_cat=3 if educ99>10 & educ99<15
replace edu_cat=4 if educ99==15
replace edu_cat=5 if educ99==16
replace edu_cat=6 if educ>16
label define educ 1 "less than HS diploma" 2 "HS Diploma" 3 "Some college/Associates Degree" 4 "Bachelor's Degree" 5 "Master's Degree" 6 "Ph.D. or Professional", replace
label val edu_cat educ
label var edu_cat "Education categories"
tab edu_cat

/*
MANY TIMES YOU WON'T BE SO LUCKY TO HAVE YOUR LABELS ALREADY ATTACHED TO THE VALUES OF A VARIABLE.
USUALLY, YOU WILL NEED TO DO SOME EXTRA RESEARCH TO FIND OUT THE CODING SCHEME BEHIND VARIABLES EXTRACTED FROM LARGER DATASETS.


BEFORE WE RUN ANY REGRESSION, IT COULD BE USEFUL TO GET A GENERAL IDEA OF THE RELATIONSHIP BETWEEN INCOME AND SOME COVARIATES.
*/
tab sex, summarize(inctot)
tab race_cat, summarize(inctot)
tab sector, summarize(inctot)
tab edu_cat, sum(inctot)

/*
NOTICE THE SIZE OF THE STANDARD DEVIATIONS.  THEY ARE NEARLY THE SIZE OF THE MEAN, WHICH WHEN LOOKING AT INCOMES IS PROBLEMATIC!  
THIS IS A GOOD INDICATION OF OUTLIERS.
IF WE PLOT A HISTOGRAM WE CAN SEE THAT OUTLIERS ARE A SERIOUS PROBLEM.
*/
hist inctot, norm
hist inctot if inctot<200000, norm

/*
IF WE DONT WANT TO DROP THE OUTLIERS, WE CAN AT LEAST MARK THEM WITH A FLAG FOR SENSITIVITY ANALYSIS.
LATER, WE CAN RUN OUR REGRESSIONS WITH AND WITHOUT THESE OBSERVATIONS TO SEE HOW MUCH THEY IMPACT OUR RESULTS.
OUTLIERS ARE STILL PART OF THE DATA, SO IT MAY NOT BE APPROPRIATE TO SEPERATE THEM
*/
gen income_flag= (inctot>200000)


/*
FOR OUR FIRST REGRESSION, WE ARE INTERESTED IN EXAMINING ONLY INDIVIDUALS WHO HAVE JOBS.  
IT WOULD NOT MAKE MUCH SENSE TO LOOK AT INDIVIDUALS' INCOMES IF THEY ARE UNEMPLOYED. 
TO MAKE SURE WE ARE LOOKING AT THE RIGHT SAMPLE, WE WILL GENERATE A DUMMY VARIABLE.
WE WILL USE THE FLAG VARIABLES WE CONSTRUCTED TO RESTRICT OUR REGRESSION TO ONLY 
EMPLOYED INDIVIDUALS WITH INCOME AND AN INDUSTRY ASSIGNED TO THEM.
*/
codebook empstat
gen employed= (empstat<14)






************SECTION IV. USING CATEGORICAL VARIABLES IN REGRESSIONS************




reg inctot age i.race_cat i.sector i.disabwrk if employed==1 

reg inctot age i.race_cat i.sector i.disabwrk if employed==1 & income_flag==0

reg inctot age ib2.race_cat i.sector i.disabwrk if employed==1 & income_flag==0, baselevels

/*
OUR INDEPENDENT VARIABLES ABOVE ARE: AGE, RACE, SECTOR, AND HAVING A WORK DISABILITY.

NOTICE THE "i." BEFORE THESE VARIABLES. THIS STANDS FOR "INDICATOR".
WHEN YOU HAVE CATEGORICAL VARIABLES, YOU CAN USE THIS PREFIX TO INCLUDE EACH CATEGORY IN THE REGRESSION AS IF IT WERE A DUMMY VARIABLE.
IT IS IMPORTANT TO REMEMBER THAT THE OMITTED CATEGORY IS WHAT IS KNOWN AS A "REFERENCE CATEGORY"
THIS MEANS ALL COEFFICIENTS REFER TO THE MISSING CATEGORY.

YOU CAN SHOW WHICH CATEGORY IS THE REFERENCE CATEGORY (REFERRED TO IN STATA AS 'BASE CATEGORY') BY ADDING THE OPTION 'baselevels'
IN OLDER VERSIONS OF STATA, YOU MUST TYPE THE PREFIX 'xi:' BEFORE THE 'reg' COMMAND 
IN ORDER TO USE THE 'i.' PREFIX BEFORE YOUR CATEGORICAL VARIABLES (e.g. xi:reg).

IF YOU DO NOT INCLUDE THE i., AND ONLY USE THE VARIABLE NAME, YOU WILL HAVE NONSENSICAL RESULTS.
FOR EXAMPLE:
reg inctot age race_cat sector disabwrk if employed==1  
*/

****INTERPRETATION OF COEFFICIENTS****
/*
HERE THE UNITS OF OUR DEPENDENT VARIABLE IS IN 2012 US DOLLARS.
WHEN WE INTERPRET COEFFICIENTS USING CATEGORICAL VARIABLES, WE WILL ESSENTIALLY BE MAKING COMPARISONS.
SO, IF WE LOOK AT THE COEFFICIENT FOR RACE_CAT=2, FOR INSTANCE, 
WE CAN SAY THAT BLACK ADULTS BETWEEN 18 AND 65 EARN ON AVERAGE [BETA] DOLLARS MORE OR LESS THAN WHITE ADULTS.
*/

*RETURNING TO THE ORIGINAL MODEL, WE WOULD LIKE TO TEST ITS PROPERTIES.
reg inctot age i.race_cat i.sector i.disabwrk if employed==1 & income_flag==0

predict e if employed==1 & income_flag==0,res
predict yhat if employed==1 & income_flag==0
twoway (scatter e yhat) (lfit e yhat)

*REMEMBER TO IMPOSE THE SAME CONDITIONS EITHER ON YOUR DIAGNOSTIC PLOTS AND TESTS OR WHEN YOU PREDICT VALUES THAT WERE IMPOSED ON YOUR REGRESSION

*WHEN WE HAVE THIS MANY OBSERVATIONS, SCATTERPLOTS JUST BECOME UNMANAGEABLE.








*************ASSUMPTIONS CHECKS************
{
***HETEROSKEDASTICITY TESTS***
reg inctot age i.race_cat i.sector i.disabwrk if employed==1 & income_flag==0

*BREUSCH-PAGAN TEST
estat hettest

*WHITE'S TEST
estat imtest, white

*BOTH TESTS SEEM TO INDICATE THAT HETEROSKEDASTICITY IS A PROBLEM.
*HO: HOMOSKEDASTICITY

*IT'S GOOD PRACTICE TO USE BOTH OF THESE TESTS, AS THEY WORK IN DIFFERENT WAYS AND HAVE DIFFERENT PROPERTIES.
*TYPICALLY, I WOULD RECOMMEND USING THE RESULTS OF MULTIPLE TESTS AS WELL AS GRAPHS TO DRAW YOUR OWN CONCLUSIONS. 
*ALSO, NOTE THAT THESE TESTS HAVE BETTER LARGE SAMPLE PROPERTIES AND WORK WORSE IN SMALL SAMPLES.


***NORMALITY OF RESIDUALS***

hist e if employed==1 & income_flag==0, norm

sktest e if employed==1 & income_flag==0

/*
YOU WILL NOTICE THAT THE SKTEST DOES NOT GIVE US ANY P-VALUES OR CHI2 STATISTICS!
THIS IS BECAUSE -SKTEST- AUTOMATICALLY ADJUSTS FOR SAMPLE SIZE IN SMALL SAMPLES.
CLEARLY OUR SAMPLE IS APPROACHING INFINITY, AND THUS WE SHOULD SPECIFY THE -NOADJUST- OPTION.
*/

sktest e if employed==1 & income_flag==0, noadjust

/*
WE SEE HERE THAT HETEROSKEDASTICITY IS DEFINITELY A PROBLEM.
IT IS OBVIOUS FROM THE SCATTER PLOT AND THE WHITE TEST AND BREUSCH PAGAN CONFIRM IT.
OUR RESIDUALS ARE NON-NORMAL ACCORDING TO BOTH THE HISTOGRAM AND SKEWNESS-KURTOSIS TEST.
*/

***MULTICOLLINEARITY***

* TO CHECK FOR MULTICOLLINEARITY, WE SHOULD CHECK THE VIF(VARIANCE INFLATION FACTOR).
vif 
*RULE OF THUMB: IF VIF > 5, COLLINEARITY MAY BE A PROBLEM.
*IN THIS CASE ONLY OUR CATEGORICAL VARIABLE HAS A VIF LARGER THAN 5, BUT THIS IS NOTHING TO BE WORRIED ABOUT
*1/VIF TELLS US WHAT PROPORTION OF AN X VARIABLE'S VARIANCE IS INDEPENDENT OF ALL THE OTHER X VARIABLES
*VIF REFLECTS THE DEGREE TO WHICH OTHER COEFFICIENTS' VARIANCES AND se ARE INCREASED DUE TO THE INCLUSION OF THAT PREDICTOR. 
*PAIRWISE CORRELATIONS ("pwcorr") CAN ALSO BE USED TO TEST FOR MULTICOLLINEARITY, BUT SINCE WE ARE USING CATEGORICAL VARIABLES IT DOES NOT MAKE THE MOST SENSE


/*
OUR MODEL SUFFERS FROM HETEROSKEDASTICITY AND NON-NORMAL RESIDUALS.  MULTICOLLINEARITY DOES NOT SEEM TO BE AN ISSUE.
THIS IS TYPICAL WHEN WORKING WITH LARGE DATASETS, AND CAN EASILY BE CORRECTED.
THE NON-NORMAL ERRORS SHOULD NOT BE AN ISSUE.  THEY DO NOT VIOLATE THE OLS ASSUMPTIONS AND BY GRAPHICAL EXAMINATION, IT APPEARS THAT THE DISTRIBUTION IS FAIRLY CLOSE TO NORMAL.
THE REJECTION OF THE NULL IN OUR STATISTICAL NORMALITY TESTS IS LIKELY A RESULT OF POOR POWER IN ASSYMETRICAL DISTRIBUTIONS.


THERE ARE A FEW WAYS TO CORRECT FOR HETEROSKEDASTICITY
1. ROBUST STANDARD ERRORS
2. LOGARITHMS!
3. HIGHER ORDER TERMS
4. INTERACTIONS BETWEEN X-VARIABLES

IT IS COMMON TO TRY DIFFERENT MODEL SPECIFICATIONS AND SEE WHAT MAKES SENSE.  EVERYTHING SHOULD BE JUSTIFIED.
IN THIS CASE WE WILL USE ROBUST STANDARD ERRORS

WE HAVE A BASIC REGRESSION PREPARED, BUT WE ARE STIL LACKING SOME KEY CONTROL VARIABLES, LIKE THE NUMBER OF ADULTS IN THE HH, SEX OF THE INDIVIDUAL, MARITAL STATUS AND EDUCATIONAL ATTAINMENT.
*/

gen female=(sex==2)
gen disability= (disabwrk==2)
*HERE WE GENERATED TWO DUMMIES: 1 FOR FEMALES AND 1 FOR INDIVIDUALS WITH A WORK DISABILITY

reg inctot age i.race_cat i.sector i.edu_cat disability female i.marst adultsinhh if employed==1 & income_flag==0, robust

/*
WE FEEL SATISFIED WITH CATEGORICAL VARIABLES WE'VE INCLUDED, BUT WE ALSO WANT TO TRY SOME DIFFERENT FUNCTIONAL FORMS OF "AGE".
IN THIS CASE, WE GENERATE AGE2 TO INCLUDE A QUADRATIC FORM OF THE VARIABLE
THIS IS PROBABLY MORE REALISTIC THAN HAVING A LINEAR SPECIFICATION.
*/

gen age2= age^2

reg inctot age age2 i.race_cat i.sector i.edu_cat disability female i.marst adultsinhh if employed==1 & income_flag==0, robust

vif

/*
NOTICE THAT I INCLUDE AGE AND AGE^2.  THIS IS A MUST IF YOU ARE INTERESTED IN QUADRATIC RELATIONSHIPS.
THE COEFFICIENTS INDICATE THAT AGE'S EFFECT ON INCOME IS NON LINEAR AND DECREASES AT SOME POINT, BUT WHEN EXACTLY?
*/


*WHEN WE DIFFERENTIATE (BASED ON THE COEFFICIENTS OF THE OUTPUT) AND SOLVE FOR THE TURNING POINT WE GET: 52.94 YEARS OLD.
*AFTER THIS AGE, INCOME BECOMES NEGATIVELY ASSOCIATED WITH Y.

twoway qfit inctot age

*NOTE THAT THE TURNING POINT IN THIS GRAPH IS NOT THE SAME AS WHAT YOU WOULD GET BY CALCULATING IT BY HAND.
*THIS GRAPH DOES NOT USE THE COEFFICIENTS WHEN CONTROLLING FOR ALL OTHER VARIABLES.
*BUT IT AT LEAST GIVES YOU A ROUGH IDEA OF WHERE THE CHANGE IN DIRECTION MIGHT BE.

*IF WE WANT AN EVEN BETTER SPECIFICATION OF FUNCTIONAL FORM, WE CAN SIMPLY USE DUMMIES.
*NOTE THAT THIS CAN ALSO BE DONE AS BEFORE WITH A CATEGORICAL VARIABLE
*WHEN WE INCLUDE ONLY DUMMIES IN THE MODEL FOR AGE, WE HAVE A "FULLY FLEXIBLE" FUNCTIONAL FORM.

gen age18to24= (age>=18 & age<26)
gen age26to35= (age>=26 & age<36)
gen age36to45= (age>=36 & age<46)
gen age46to55= (age>=46 & age<56)
gen age56to65= (age>=56 & age<66)

reg inctot age18to24 age26to35 age36to45 age46to55 age56to65 i.race_cat i.sector i.edu_cat disability female i.marst adultsinhh if employed==1 & income_flag==0, robust
*WHEN USING CATEGORICAL VARIABLES IT IS ALSO IMPORTANT TO KNOW WHETHER THE ESTIMATES FOR THE CATEGORIES ARE STATISITICALLY DIFFERENT FROM ONE ANOTHER
*IN THIS CASE WE COULD USE AN F-TEST
*HERE WE TEST WHETHER THE ESTIMATE FOR AFRICAN AMERICAN IS STATISTICALLY DIFFERENT THAN NATIVE AMERICAN
test 2.race_cat==3.race_cat

*DIVORCED VS SEPARATED
codebook marst
test 2.marst==3.marst

test 3.marst==4.marst

/*
YOU WILL NOTICE THAT ONE OF THE AGE DUMMIES HAS BEEN OMITTED FROM THE REGRESSION.  
THIS IS BECAUSE OF PERFECT COLLINEARITY.
WHEN INCLUDING DUMMIES IN A REGRESSION, THEY MUST BE MUTUALLY EXCLUSIVE 
(I.E. ONE INDIVIDUAL CANNOT BE INCLUDED IN TWO DUMMIES OF THE SAME VARIABLE) 
AND YOU CAN ONLY INCLUDE N-1 DUMMIES.
THE OMITTED DUMMY VARIABLE WILL ALWAYS BE YOUR REFERENCE CATEGORY, AND ALL OF YOUR 
INTERPRETATION SHOULD BE IN THE CONTEXT OF THAT REFERENCE CATEGORY.
SO, IF AGE18TO24 IS OMITTED, THEN ALL COEFFICIENTS FOR THE AGE DUMMIES ARE 
INTERPRETTED AS: INDIVIDUALS AGE 26 TO 35 EARN [BETA] DOLLARS MORE IN TOTAL INCOME THAN THOSE AGE 18 TO 24, ETC.

HOW CAN WE INTERPRET THESE COEFFICIENTS?  IT MAY SEEM DAUNTING WITH SO MANY CATEGORIES 
AND CONTINUOUS VARIABLES PRESENT, BUT IT IS ACTUALLY QUITE EASY.
IF WE TAKE THE COEFFICIENT FOR RACE==2, FOR EXAMPLE, WE INTERPRET IT AS FOLLOWS:
BLACK INDIVIDUALS EARN $2627.226 LESS THAN WHITE INDIVIDUALS, 
WHEN CONTROLLING FOR AGE, SECTOR OF EMPLOYMENT, EDUCATIONAL ATTAINMENT, SEX, 
MARITAL STATUS & THE NUMBER OF ADULTS IN THE HOUSEHOLD.
*/


predict e2 if employed==1 & income_flag==0, res
predict yhat2 if employed==1 & income_flag==0
twoway (scatter e2 yhat2) (lfit e2 yhat2)
estat hettest
hist e2, norm
sktest e2, noadjust

}






************SECTION V. INTERACTION TERMS*********
{
*IT MAY ALSO BE OF INTEREST TO LOOK AT HOW VARIABLES INTERACT WITH ONE ANOTHER.
*IN THIS CASE, WE WANT TO SEE HOW WOMEN COMPARE TO MEN AND TO EACH OTHER ACROSS AND WITHIN RACIAL GROUPS. 

/*
INTERACTION TERMS ARE MULTIPLICATIVE TERMS AND CAN BE DEFINED MANUALLY BY MAKING NEW VARIABLES, BUT STATA ALSO HAS A BUILT-IN COMMAND
FOR RUNNING INTERACTIONS. 
# BETWEEN TWO VARIABLES WILL GIVE ONLY THE INTERACTION TERM
## BETWEEN TWO VARIABLES WILL GIVE BOTH THE INTERACTION TERMS AND THE RESPECTIVE BASE EFFECTS (SO YOU DON'T HAVE TO INCLUDE THEM SEPARATELY).

THE REGRESSION BELOW CAN ALSO BE RUN AS (IN OLDER VERSIONS OF STATA:
xi: reg  inctot age26to35 age36to45 age46to55 age56to65 i.sector i.edu_cat disability i.marst adultsinhh i.race_cat*female if employed==1 & income_flag==0, robust
*/

*DUMMY-CATEGORICAL INTERACTION
reg inctot age26to35 age36to45 age46to55 age56to65 i.sector i.edu_cat disability i.marst adultsinhh i.race_cat##i.female if employed==1 & income_flag==0, robust baselevels


*DUMMY-CONTINUOUS INTERACTION WITH SHARED INTERCEPT
gen femage= female*age
br female age femage
reg inctot age femage
*THIS ASSUMPTION IS VERY DIFFICULT TO SUPPORT, SO IT IS NOT COMMONLY DONE THIS WAY

*DUMMY-CONTINUOUS INTERACTION WITH UNIQUE INTERCEPTS
reg inctot age i.female femage
*THIS CAN ALSO BE WRITTEN AS (:
reg inctot i.female##c.age
*OR
reg inctot age i.female i.female#c.age
*NOTE THAT CONTINUOUS VARIABLES IN INTERACTIONS NEED TO BE PREFIXED WITH c.


*DUMMY-QUADRATIC INTERACTION WITH SHARED INTERCEPT
gen femage2=female*age2
reg inctot age age2 femage femage2
*THIS ASSUMPTION IS VERY DIFFICULT TO SUPPORT, SO IT IS NOT COMMONLY DONE THIS WAY

*DUMMY-QUADRATIC INTERACTION WITH UNIQUE INTERCEPTS
reg inctot age age2 female femage femage2
}



























log close
cmdlog close








/*
GOOD SUPPORTING MATERIAL:
https://stats.idre.ucla.edu/stata/webbooks/reg/
*/
